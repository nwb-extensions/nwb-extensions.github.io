{"ndx-miniscope-record": {"ref": "ndx-miniscope-record", "record_url": "https://github.com/nwb-extensions/ndx-miniscope-record", "last_updated": "2019-10-16T05:56:05Z", "name": "ndx-miniscope", "version": "0.2.2", "src": "https://github.com/bendichter/ndx-miniscope", "pip": "https://pypi.org/project/ndx-miniscope/", "license": "BSD", "maintainers": ["bendichter"], "readme": "# ndx-miniscope Extension for NWB:N\n\nThis is a Neurodata Extension (NDX) for Neurodata Without Borders: Neurophysiology (NWB:N) 2.0 that provides an extension to Device to hold meta-data collected by the Miniscope device."}, "ndx-simulation-output-record": {"ref": "ndx-simulation-output-record", "record_url": "https://github.com/nwb-extensions/ndx-simulation-output-record", "last_updated": "2019-10-16T06:23:42Z", "name": "ndx-simulation-output", "version": "0.2.5", "src": "https://github.com/bendichter/ndx-simulation-output", "pip": "https://pypi.org/project/ndx-simulation-output", "license": "BSD", "maintainers": ["bendichter"], "readme": "# ndx-simulation-output Extension for NWB:N\n\n## An extension for output data of large-scale simulations\n Developed in collaboration between the Soltesz lab and the Allen Institute during [NWB Hackathon #4](https://github.com/NeurodataWithoutBorders/nwb_hackathons/tree/master/HCK04_2018_Seattle/Projects/NetworkOutput) by Ben Dichter*, Kael Dai*, Aaron Milstein, Yazan Billeh, Andrew Tritt, Jean-Christophe Fillion-Robin, Anton Akhipov, Oliver Ruebel, Nicholas Cain, Kristofer Bouchard, and Ivan Soltesz\n\nThis extension defines two NWB neuorodata_types, `CompartmentSeries` and `Compartments`. `CompartmentSeries` stores continuous data (e.g. membrane potential, calcium concentration) from many compartments of many cells, and scales to hundreds of thousands of compartments. `Compartments` stores the meta-data associated with those compartments, and is stored in `SimulationMetaData`.\n\n![Image of CompartmentSeries](multicompartment_schema_1.png)\n\n\n## Guide\n### python\n#### installation\n```\npip install ndx-simulation-output\n```\n\n#### usage\n```python\nfrom pynwb import NWBHDF5IO, NWBFile\nfrom datetime import datetime\nfrom ndx_simulation_output import CompartmentSeries, Compartments, SimulationMetaData\nimport numpy as np\n\n\ncompartments = Compartments()\ncompartments.add_row(number=[0, 1, 2, 3, 4], position=[0.1, 0.2, 0.3, 0.4, 0.5])\ncompartments.add_row(number=[0], position=[np.nan])\n\nnwbfile = NWBFile('description', 'id', datetime.now().astimezone())\n\nnwbfile.add_lab_meta_data(SimulationMetaData(compartments=compartments))\ncs = CompartmentSeries('membrane_potential', np.random.randn(10, 6),\n                       compartments=compartments, unit='V', rate=100.)\nnwbfile.add_acquisition(cs)\n\nwith NWBHDF5IO('test_compartment_series.nwb', 'w') as io:\n    io.write(nwbfile)\n```\n\nconversion from SONTATA:\n```python\nfrom ndx_simulation_output.io import sonata2nwb\n\nsonata2nwb('sonata_fpath', 'save_path')\n```\n\n### MATLAB\n#### installation\n\ncommand line:\n```\ngit clone https://github.com/bendichter/ndx-simulation-output.git\n```\n\nin matlab:\n```matlab\ngenerateExtension('/path/to/ndx-simulation-output/spec/ndx-simulation-output.namespace.yaml');\n```\n\n#### usage\n```matlab\nnwb = nwbfile()\n\n[number, number_index] = util.create_indexed_column( ...\n    {[0, 1, 2, 3, 4], 0}, '/acquisition/compartments/number');\n\n[position, position_index] = util.create_indexed_column( ...\n    {[0.1, 0.2, 0.3, 0.4, 0.5], 0}, '/acquisition/compartments/position');\n\ncompartments = types.ndx_simulation_output.Compartments( ...\n    'colnames', {'number', 'position'}, ...\n    'description', 'membrane potential from various compartments', ...\n    'id', types.core.ElementIdentifiers('data', int64(0:5)));\n\ncompartments.position = position;\ncompartments.position_index = position_index;\ncompartments.number = number;\ncompartments.number_index = number_index;\n\nmembrane_potential = types.ndx_simulation_output.CompartmentSeries( ...\n    'data', randn(10,6), ...\n    'compartments', types.untyped.SoftLink('/acquisition/compartments'), ...\n    'data_unit', 'V', ...\n    'starting_time_rate', 100., ...\n    'starting_time', 0.0);\n    \nsimulation = types.ndx_simulation_output.SimulationMetaData('compartments', compartments);\n    \nnwb.general.set('simulation', simulation);\n\nnwb.acquisition.set('membrane_potential', membrane_potential);\n```\n\n## Talks\nBen Dichter*, Kael Dai*, Aaron Milstein, Yazan Billeh, Andrew Tritt, Jean-Christophe Fillion-Robin, Anton Akhipov, Oliver Ruebel, Nicholas Cain, Kristofer Bouchard, Ivan Soltesz. NWB extension for storing results of large-scale neural network simulations. NeuroInformatics. Montreal, Canada (2018). [video](https://www.youtube.com/watch?v=uuYQW0EE2GY).\n"}, "ndx-ecog-record": {"ref": "ndx-ecog-record", "record_url": "https://github.com/nwb-extensions/ndx-ecog-record", "last_updated": "2019-10-16T08:20:22Z", "name": "ndx-ecog", "version": "0.1.1", "src": "https://github.com/ben-dichter-consulting/ndx-ecog", "pip": "https://pypi.org/project/ndx-ecog/", "license": "BSD", "maintainers": ["bendichter"], "readme": "# ndx-ecog Extension for NWB:N\n\nAuthor: Ben Dichter\n\nThere are three data types, `Surface`, `CorticalSurfaces`, and `ECoGSubject`. `CorticalSurfaces` is simply a group (like a folder) to put `Surface` objects into. `Surface` holds surface mesh data (vertices and triangular faces) for sections of cortex. `ECoGSubject` is an extension of `Subject` that allows you to add the `CorticalSurfaces` object to `/general/subject`.\n\n## Usage\n\n### python\n\ninstall:\n```bash\npip install ndx_ecog\n```\n\nwrite:\n```python\nimport pynwb\nfrom ndx_ecog import CorticalSurfaces, ECoGSubject\n\nnwbfile = pynwb.NWBFile(...)\n\n...\n\ncortical_surfaces = CorticalSurfaces()\n## loop me\n    cortical_surfaces.create_surface(name=name, faces=faces, vertices=veritices)\n##\nnwbfile.subject = ECoGSubject(cortical_surfaces=cortical_surfaces)\n```\n\nYou can optionally attach images of the subject's brain:\n```python\nfrom pynwb.base import Images\nfrom pynwb.image import GrayscaleImage\n\nsubject.images = Images(name='subject images', images=[GrayscaleImage('image1', data=image_data)])\n```\n\nread:\n```python\nimport nwbext_ecog\nfrom pynwb import NWBHDF5IO\nio = NWBHDF5IO('path_to_file.nwb','r')\nnwb = io.read()\nnwb.subject.cortical_surfaces\n```\n\n### MATLAB\ninstall:\n```matlab\ngenerateExtension('/path/to/ndx-ecog/spec/ndx-ecog.namespace.yaml');\n```\n\nwrite:\n```matlab\ncortical_surfaces = types.ecog.CorticalSurfaces;\n\n%%% loop me\n    surf = types.ecog.Surface('faces', faces, 'vertices', vertices);\n    cortical_surfaces.surface.set(surface_name, surf);\n%%%\n\nfile.subject = types.ecog.ECoGSubject(name, cortical_surfaces);\n```\n"}, "ndx-fret-record": {"ref": "ndx-fret-record", "record_url": "https://github.com/nwb-extensions/ndx-fret-record", "last_updated": "2020-01-24T21:49:16Z", "name": "ndx-fret", "version": "0.1.1", "src": "https://github.com/ben-dichter-consulting/ndx-fret", "pip": "https://pypi.org/project/ndx-fret/", "license": "BSD", "maintainers": ["luiztauffer", "bendichter"], "readme": "# ndx-fret\n[![PyPI version](https://badge.fury.io/py/ndx-fret.svg)](https://badge.fury.io/py/ndx-fret)\n\nNWB extension for storing Fluorescence Resonance Energy Transfer (FRET) experimental data.\nA collaboration with [Jaeger Lab](https://scholarblogs.emory.edu/jaegerlab/), [Emory University](https://www.emory.edu/home/index.html) and [The Kavli Foundation](https://www.kavlifoundation.org/).\n\n<p align=\"center\">\n<img src=\"media/FRET_schematic.png\" width=\"400\">\n</p>\n\n### Python Installation\n```bash\npip install ndx-fret\n```\n\n### Python Usage\n```python\nfrom pynwb import NWBFile, NWBHDF5IO\nfrom pynwb.device import Device\nfrom pynwb.ophys import OpticalChannel\nfrom ndx_fret import FRET, FRETSeries\n\nfrom datetime import datetime\nimport numpy as np\n\nnwb = NWBFile('session_description', 'identifier', datetime.now().astimezone())\n\n# Create and add device\ndevice = Device(name='Device')\nnwb.add_device(device)\n\n# Create optical channels\nopt_ch_d = OpticalChannel(\n    name='optical_channel',\n    description='optical_channel_description',\n    emission_lambda=529.\n)\nopt_ch_a = OpticalChannel(\n    name='optical_channel',\n    description='optical_channel_description',\n    emission_lambda=633.\n)\n\n# Create FRET\nfs_d = FRETSeries(\n    name='donor',\n    fluorophore='mCitrine',\n    optical_channel=opt_ch_d,\n    device=device,\n    description='description of donor series',\n    data=np.random.randn(100, 10, 10),\n    rate=200.,\n)\nfs_a = FRETSeries(\n    name='acceptor',\n    fluorophore='mKate2',\n    optical_channel=opt_ch_a,\n    device=device,\n    description='description of acceptor series',\n    data=np.random.randn(100, 10, 10),\n    rate=200.,\n)\n\nfret = FRET(\n    name='FRET',\n    excitation_lambda=482.,\n    donor=fs_d,\n    acceptor=fs_a\n)\nnwb.add_acquisition(fret)\n\n# Write nwb file\nwith NWBHDF5IO('test_fret.nwb', 'w') as io:\n    io.write(nwb)\n    print('NWB file written')\n\n# Read nwb file and check its content\nwith NWBHDF5IO('test_fret.nwb', 'r', load_namespaces=True) as io:\n    nwb = io.read()\n    print(nwb)\n```\n"}, "ndx-icephys-meta-record": {"ref": "ndx-icephys-meta-record", "record_url": "https://github.com/nwb-extensions/ndx-icephys-meta-record", "last_updated": "2022-04-20T19:15:11Z", "name": "ndx-icephys-meta", "version": "0.1.0", "src": "https://github.com/oruebel/ndx-icephys-meta", "pip": "https://pypi.org/project/ndx-icephys-meta/", "license": "BSD 3-Clause", "maintainers": ["oruebel"], "readme": "# [Deprecated] ndx-icephys-meta Extension for NWB\n\n**Status:** The changes from this extension have been integrated with NWB and are part of then [NWB 2.4 release](https://nwb-schema.readthedocs.io/en/latest/format_release_notes.html#aug-11-2021). Use of this extension is deprecated. \n\n**Overview:** This extension implements the icephys extension proposal described [here](https://docs.google.com/document/d/1cAgsXv26BmQoVfa7Greyxs0oc4IGH-t5aJsm-AwUAAE/edit). The extension is intended to evaluate and explore the practical use of the proposed changes as well as to provide a reference implementation with the goal to ease integration of the proposed changes with NWB.\n\n## Install\n\n```\npython setup.py develop\n```\n\nThe extension is now also available on pip and can be installed via:\n\n```\npip install ndx-icephys-meta\n```\n\nThe extension is also listed in the (NDX catalog)[https://nwb-extensions.github.io/]. See [here](https://github.com/nwb-extensions/ndx-icephys-meta-record) for the catalog metadata record.\n\n\n## Building the spec documentation\n\n```\ncd docs\nmake html\n```\n\nThis generates the specification docs directly from the YAML specifciation in the ``spec`` folder. The generated docs are stored in ``/docs/build``\n\n## Running the unit tests\n\n```\npython src/pynwb/ndx_icephys_meta/test/test_icephys.py\n```\n\n## Content\n\n* ``spec/`` : YAML specification of the extension\n* ``docs/`` : Sources for building the specification docs from the YAML spec\n* ``src/spec/create_extension_spec.py`` : Python source file for creating the specification\n* ``src/pynwb/`` : Sources for Python extensions and examples\n    * ``ndx_icephys_meta`` : Python package with extensions to PyNWB for read/write of extension data\n    * ``ndx_icephys_meta/test`` : Unit test for the Python extension\n    * ``ndx_icephys_meta/icephys.py`` : PyNWB Container classes\n    * ``ndx_icephys_meta/io/icephys.py`` : PyNWB ObjectMapper classes\n    * ``examples`` : Examples illustrating the use of the extension in Python\n\n\n## Example\n\nExamples for the Python extension are available at ``src/pynwb/examples``. The unit tests in ``src/pynwb/ndx_icephys_meta/test`` can also serve as additional examples.\n\nThe following shows a simple example. The steps with (A) - (E) in the comments are the main new steps for this extension. The other parts of the code are standard NWB code.\n\n```python\nfrom datetime import datetime\nfrom dateutil.tz import tzlocal\nimport numpy as np\nfrom pynwb.icephys import VoltageClampStimulusSeries, VoltageClampSeries\nfrom pynwb import NWBHDF5IO\nfrom ndx_icephys_meta.icephys import ICEphysFile  # Import the extension\n\n# Create an ICEphysFile\nnwbfile = ICEphysFile(session_description='my first recording',\n                      identifier='EXAMPLE_ID',\n                      session_start_time=datetime.now(tzlocal()))\n\n# Add a device\ndevice = nwbfile.create_device(name='Heka ITC-1600')\n\n# Add an intracellular electrode\nelectrode = nwbfile.create_ic_electrode(name=\"elec0\",\n                                        description='a mock intracellular electrode',\n                                        device=device)\n\n# Create an ic-ephys stimulus\nstimulus = VoltageClampStimulusSeries(\n            name=\"stimulus\",\n            data=[1, 2, 3, 4, 5],\n            starting_time=123.6,\n            rate=10e3,\n            electrode=electrode,\n            gain=0.02)\n\n# Create an ic-response\nresponse = VoltageClampSeries(\n            name='response',\n            data=[0.1, 0.2, 0.3, 0.4, 0.5],\n            conversion=1e-12,\n            resolution=np.nan,\n            starting_time=123.6,\n            rate=20e3,\n            electrode=electrode,\n            gain=0.02,\n            capacitance_slow=100e-12,\n            resistance_comp_correction=70.0)\n\n# (A) Add an intracellular recording to the file\nir_index = nwbfile.add_intracellular_recording(electrode=electrode,\n                                               stimulus=stimulus,\n                                               response=response)\n\n# (B) Add a list of sweeps to the sweeps table\nsweep_index = nwbfile.add_ic_sweep(recordings=[ir_index, ])\n\n# (C) Add a list of sweep table indices as a sweep sequence\nsequence_index = nwbfile.add_ic_sweep_sequence(sweeps=[sweep_index, ])\n\n# (D) Add a list of sweep sequence table indices as a run\nrun_index = nwbfile.add_ic_run(sweep_sequences=[sequence_index, ])\n\n# (E) Add a list of run table indices as a condition\nnwbfile.add_ic_condition(runs=[run_index, ])\n\n# Write our test file\ntestpath = \"test_icephys_file.h5\"\nwith NWBHDF5IO(testpath, 'w') as io:\n    io.write(nwbfile)\n\n# Read the data back in\nwith NWBHDF5IO(testpath, 'r') as io:\n    infile = io.read()\n    print(infile)\n\n```\n"}, "ndx-events-record": {"ref": "ndx-events-record", "record_url": "https://github.com/nwb-extensions/ndx-events-record", "last_updated": "2022-11-15T06:37:13Z", "name": "ndx-events", "version": "0.2.0", "src": "https://github.com/rly/ndx-events", "pip": "https://pypi.org/project/ndx-events/", "license": "BSD", "maintainers": ["rly"], "readme": "# ndx-events Extension for NWB\n\nThis is an NWB extension for storing timestamped event data and TTL pulses.\n\nEvents can be:\n1. **Simple events**. These are stored in the `Events` type. The `Events` type consists of only a name, a description,\nand a 1D array of timestamps. This should be used instead of a `TimeSeries` when the time series has no data.\n2. **Labeled events**. These are stored in the `LabeledEvents` type. The `LabeledEvents` type expands on the `Events`\ntype by adding 1) a 1D array of integer values (data) with the same length as the timestamps and 2) a 1D array of\nlabels (labels) associated with each unique integer value in the data array. The data values are indices into the\narray of labels. The `LabeledEvents` type can be used to encode additional information about individual events,\nsuch as the reward values for each reward event.\n3. **TTL pulses**. These are stored in the `TTLs` type. The `TTLs` type is a subtype of the `LabeledEvents` type\nspecifically for TTL pulse data. A single instance should be used for all TTL pulse data. The pulse value (or channel)\nshould be stored in the 1D data array, and the labels associated with each pulse value (or channel)\nshould be stored in the 1D array of labels.\n4. **Annotated events**. These are stored in the `AnnotatedEventsTable` type. The `AnnotatedEventsTable` type is a\nsubtype of `DynamicTable`, where each row corresponds to a different event type. The table has a ragged\n(variable-length) 1D column of event times, such that each event type (row) is associated with an array of event times.\nUnlike for the other event types, users can add their own custom columns to annotate each event type or event time.\nThis can be useful for storing event metadata related to data preprocessing and analysis, such as marking bad events.\n\nThis extension was developed by Ryan Ly, Ben Dichter, Oliver R\u00fcbel, and Andrew Tritt. Information about the rationale,\nbackground, and alternative approaches to this extension can be found here:\nhttps://docs.google.com/document/d/1qcsjyFVX9oI_746RdMoDdmQPu940s0YtDjb1en1Xtdw\n\n## Installation\n\n```\npip install ndx-events\n```\n\n## Example usage\n\n```python\nfrom datetime import datetime\n\nfrom pynwb import NWBFile, NWBHDF5IO\nfrom ndx_events import LabeledEvents, AnnotatedEventsTable\n\n\nnwb = NWBFile(\n    session_description='session description',\n    identifier='cool_experiment_001',\n    session_start_time=datetime.now().astimezone()\n)\n\n# create a new LabeledEvents type to hold events recorded from the data acquisition system\nevents = LabeledEvents(\n    name='LabeledEvents',\n    description='events from my experiment',\n    timestamps=[0., 0.5, 0.6, 2., 2.05, 3., 3.5, 3.6, 4.],\n    resolution=1e-5,  # resolution of the timestamps, i.e., smallest possible difference between timestamps\n    data=[0, 1, 2, 3, 5, 0, 1, 2, 4],\n    labels=['trial_start', 'cue_onset', 'cue_offset', 'response_left', 'response_right', 'reward']\n)\n\n# add the LabeledEvents type to the acquisition group of the NWB file\nnwb.add_acquisition(events)\n\n# create a new AnnotatedEventsTable type to hold annotated events\nannotated_events = AnnotatedEventsTable(\n    name='AnnotatedEventsTable',\n    description='annotated events from my experiment',\n    resolution=1e-5  # resolution of the timestamps, i.e., smallest possible difference between timestamps\n)\n# add a custom indexed (ragged) column to represent whether each event time was a bad event\nannotated_events.add_column(\n    name='bad_event',\n    description='whether each event time should be excluded',\n    index=True\n)\n# add an event type (row) to the AnnotatedEventsTable instance\nannotated_events.add_event_type(\n    label='Reward',\n    event_description='Times when the subject received juice reward.',\n    event_times=[1., 2., 3.],\n    bad_event=[False, False, True],\n    id=3\n)\n\n# create a processing module in the NWB file to hold processed events data\nevents_module = nwb.create_processing_module(\n    name='events',\n    description='processed event data'\n)\n\n# add the AnnotatedEventsTable instance to the processing module\nevents_module.add(annotated_events)\n\n# write nwb file\nfilename = 'test.nwb'\nwith NWBHDF5IO(filename, 'w') as io:\n    io.write(nwb)\n\n# read nwb file and check its contents\nwith NWBHDF5IO(filename, 'r', load_namespaces=True) as io:\n    nwb = io.read()\n    print(nwb)\n```\n\nThis extension was created using [ndx-template](https://github.com/nwb-extensions/ndx-template).\n"}, "ndx-nirs-record": {"ref": "ndx-nirs-record", "record_url": "https://github.com/nwb-extensions/ndx-nirs-record", "last_updated": "2022-11-15T06:37:40Z", "name": "ndx-nirs", "version": "0.3.0", "src": "https://github.com/agencyenterprise/ndx-nirs", "pip": "https://pypi.org/project/ndx-nirs/", "license": "BSD 3-Clause", "maintainers": ["sumner15", "dsleiter", "ribeirojose"], "readme": "# ndx-nirs Extension for NWB\n\nThis is an [NWB](https://www.nwb.org/) extension for storing and sharing near-infrared spectroscopy (NIRS) data.\n\nIf you're new to NWB: \"Neurodata Without Borders (NWB) is a data standard for neurophysiology, providing neuroscientists with a common standard to share, archive, use, and build common analysis tools for neurophysiology data.\" ([source](https://www.nwb.org/nwb-neurophysiology/))\n\nThis extension defines the data specification for NIRS data in addition to providing a python API for reading and writing .nwb files containing data that follows this specification. The python package can be used with [pyNWB](https://github.com/NeurodataWithoutBorders/pynwb).\n\nThis extension has been officially accepted into the [Neurodata Extensions Catalog](https://nwb-extensions.github.io/) and can be found there along with other accepted extensions.\n\n## Introduction to NIRS\n\nNIRS uses near-infrared sources (from 780 nm to 2500 nm) to assess brain function by detecting changes in blood hemoglobin (Hb) concentrations. \n\nAs neural activity changes, blood volume and the concentration of hemoglobin in the local area changes through the neurovascular coupling phenomenon. NIRS techniques requires optical sources with two or more wavelengths in the near-infrared spectrum. One must have a wavelength above and one below the isosbestic point of 810 nm - the point at which deoxygenated hemoglobin (deoxy-Hb) and oxygenated hemoglobin (oxy-Hb) have identical absorption coefficients. Using the modified Beer-Lambert law (mBLL), NIRS techniques reveal  changes in hemoglobin concentration. NIRS monitors hemoglobin levels through these optical absorption coefficients as a proxy for localized brain activity.\n\n## Purpose of the extension\n\nThe user-base of NIRS techniques continues to grow. In addition, NIRS techniques are often used in conjunction with other brain recording techniques (e.g. EEG) and/or use common stimuli or behavioral paradigms. The NWB NIRS extension provides a data standard for neuroscientist to share, archive, use, and build analysis tools for NIRS data. \n\nIntegration of NIRS into the NWB data standard affords all NIRS users interoperability with many of the data storage, processing, analysis, and visualization tools already integrated within NWB. \n\n## Modes of NIRS currently supported\n\nThis extension currently explicitly supports: \n\n1. Continuous Wave\n    - see `NIRSDevice.nirs_mode` \n2. Frequency-Domain\n    - see `NIRSDevice.nirs_mode` and `NIRSDevice.frequency`\n3. Time-Domain \n    - see `NIRSDevice.nirs_mode`, `NIRSDevice.time_delay`, and `NIRSDevice.time_delay_width`\n4. Diffuse Correlation Spectroscopy\n    - see `NIRSDevice.nirs_mode`, `NIRSDevice.correlation_time_delay`, and `NIRSDevice.correlation_time_delay_width`\n\nIn addition, it includes support for fluorescent versions of each of these techniques.\n  - see `NIRSChannelsTable.emssion_wavelength`\n\nOther NIRS modalities are supported implicitly. We acknowledge that NIRS is a fast-growing recording method with new modalities constantly under development. For this reason, it is possible to define other useful parameters using the `NIRSDevice.additional_parameters` field. Future version of NWB NIRS will add native support for new NIRS modalities.\n\n## Related data standards \n\nThe NWB NIRS neurodata type was inspired by the [SNIRF](https://fnirs.org/resources/software/snirf/) data specification ([Github](https://github.com/fNIRS/snirf)). Many of the data fields can be directly mapped from SNIRF to NWB and vice-versa. We expect to release a SNIRF<->NWB conversion tool in the near future to improve compatibility between data standards and ease the burden of conversion on NIRS researchers.\n\n## NWB NIRS data architecture\n\nThe two principal neurodata types of this extension are ``NIRSDevice``, which extends the `Device` data type and holds information about the NIRS hardware and software configuration, and ``NIRSSeries``, which contains the timeseries data collected by the NIRS device.\n\n``NIRSSourcesTable``, ``NIRSDetectorsTable``, and ``NIRSChannelsTable`` are children of ``NIRSDevice`` which describe the source and detector layout as well as the wavelength-specific optical channels that are measured.\n\nEach row of ``NIRSChannelsTable`` represents a specific source and detector pair along with the source illumination wavelength (and optionally, in the case of fluorescent spectroscopy, the emission/detection wavelength). The channels in this table correspond have a 1-to-1 correspondence with the data columns in ``NIRSSeries``.\n\n![ndx-nirs UML](https://github.com/agencyenterprise/ndx-nirs/raw/main/docs/source/images/ndx-nirs-uml.png)\n\n### Defined neurodata types\n\n1. ``NIRSSourcesTable`` stores rows for each optical source of a NIRS device. ``NIRSSourcesTable`` columns includes:\n    - ``label`` - the label of the source.\n    - ``x``, ``y``, and ``z`` - the coordinates in meters of the optical source (``z`` is optional).\n\n2. ``NIRSDetectorsTable`` stores rows for each of the optical detectors of a NIRS device. ``NIRSDetectorsTable`` columns includes:\n    - ``label`` - the label of the detector.\n    - ``x``, ``y``, and ``z`` - the coordinates in meters of the optical detector (``z`` is optional).\n\n3. ``NIRSChannelsTable`` stores rows for each physiological channel, which is defined by source-detector pairs, where sources & detectors are referenced via ``NIRSSourcesTable`` and ``NIRSDetectorsTable``. ``NIRSChannelsTable`` columns includes:\n    - ``label`` - the label of the channel.\n    - ``source`` - a reference to the optical source in ``NIRSSourcesTable``.\n    - ``detector`` - a reference to the optical detector in ``NIRSDetectorsTable``.\n    - ``source_wavelength`` - the wavelength of light in nm emitted by the source for this channel.\n    - ``emission_wavelength`` - the wavelength of light in nm emitted by the fluorophone (optional; only used for fluorescent spectroscopy).\n    - ``source_power`` - the power of the source in mW used for this channel (optional).\n    - ``detector_gain`` - the gain applied to the detector for this channel (optional).\n    \n4. ``NIRSDevice`` defines the NIRS device itself and includes the following required fields:\n    - ``name`` - a unique name for the device.\n    - ``description`` - a free-form text description of the device.\n    - ``manufacturer`` - the name of the manufacturer of the device.\n    - ``channels`` - a table of the optical channels available on this device (references ``NIRSChannelsTable``).\n    - ``sources`` - the optical sources of this device (references ``NIRSSourcesTable``).\n    - ``detectors`` - the optical detectors of this device (references ``NIRSDetectorsTable``).\n    - ``nirs_mode`` - the mode of NIRS measurement performed with this device (e.g., 'continuous-wave', 'frequency-domain', etc.).\n        \n   ``NIRSDevice`` also includes several optional attributes to be used in parallel with specific ``nirs_mode`` values:\n    - ``frequency`` - the modulation frequency in Hz for frequency domain NIRS (optional).\n    - ``time_delay`` - the time delay in ns used for gated time domain NIRS (TD-NIRS) (optional).\n    - ``time_delay_width`` - the time delay width in ns used for gated time domain NIRS (optional).\n    - ``correlation_time_delay`` - the correlation time delay in ns for diffuse correlation spectroscopy NIRS (optional).\n    - ``correlation_time_delay_width`` - the correlation time delay width in ns for diffuse correlation spectroscopy NIRS (optional).\n    - ``additional_parameters`` - any additional parameters corresponding to the NIRS device/mode that are useful for interpreting the data (optional).\n\n5. ``NIRSSeries`` stores the actual timeseries data collected by the NIRS device and includes:\n    - ``name`` - a unique name for the NIRS timeseries.\n    - ``description`` - a description of the NIRS timeseries.\n    - ``timestamps`` - the timestamps for each row of ``data`` in seconds.\n    - ``channels`` - a ``DynamicTableRegion`` mapping to the appropriate channels in a ``NIRSChannelsTable``.\n    - ``data`` - the actual numeric raw data measured by the NIRS system. It is a 2D array where the columns correspond to ``channels`` and the rows correspond to ``timestamps``.\n\n## Installation\n\nTo install from PyPI use pip:\n\n```\n$ pip install ndx-nirs\n```\n\nTo install after cloning the extension repo from github, execute the following from the root of the repo:\n\n```\n$ pip install .\n```\n\nFor development purposes, it might be useful to install in editable mode:\n\n```\n$ pip install -e .\n```\n\n## Usage\n\n```python\nfrom datetime import datetime\n\nimport numpy as np\n\nfrom hdmf.common import DynamicTableRegion\nfrom pynwb import NWBHDF5IO\nfrom pynwb.file import NWBFile, Subject\n\nfrom ndx_nirs import NIRSSourcesTable, NIRSDetectorsTable, NIRSChannelsTable, NIRSDevice, NIRSSeries\n\n\n##### create some example data to add to the NWB file #####\n\n# create NIRS source & detector labels\nsource_labels = [\"S1\", \"S2\"]\ndetector_labels = [\"D1\", \"D2\"]\n\n# create NIRS source & detector positions as a numpy array\n# with dims: [num sources/detectors rows x 2 columns (for x, y)]\nsource_pos = np.array([[-2.0, 0.0], [-4.0, 5.6]])\ndetector_pos = np.array([[0.0, 0.0], [-4.0, 1.0]])\n\n# create a list of source detector pairs (pairs of indices)\nsource_detector_pairs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n\n\n##### create NWB file using the example data above #####\n\n# create a basic NWB file\nnwb = NWBFile(\n    session_description=\"A NIRS test session\",\n    identifier=\"nirs_test_001\",\n    session_start_time=datetime.now().astimezone(),\n    subject=Subject(subject_id=\"nirs_subj_01\"),\n)\n\n\n# create and populate a NIRSSourcesTable containing the\n# label and location of optical sources for the device\nsources = NIRSSourcesTable()\n# add source labels & positions row-by-row\nfor i_source in range(0, len(source_labels)):\n    sources.add_row(\n        label=source_labels[i_source],\n        x=source_pos[i_source, 0],\n        y=source_pos[i_source, 1],\n    )\n\n\n# create and populate a NIRSDetectorsTable containing the\n# label and location of optical sources for the device\ndetectors = NIRSDetectorsTable()\n# add a row for each detector\nfor i_detector in range(0, len(detector_labels)):\n    detectors.add_row(\n        label=detector_labels[i_detector],\n        x=detector_pos[i_detector, 0],\n        y=detector_pos[i_detector, 1],\n    )  # z-coordinate is optional\n\n\n# create a NIRSChannelsTable which defines the channels\n# between the provided sources and detectors\nchannels = NIRSChannelsTable(sources=sources, detectors=detectors)\n# each channel is composed of a single source, a single detector, and the wavelength\n# most source-detector pairs will use two separate wavelengths, and have two channels\nfor i_source, i_detector in source_detector_pairs:\n    for wavelength in [690.0, 830.0]:\n        # for the source and detector parameters, pass in the index of\n        # the desired source (detector) in the sources (detectors) table\n        channels.add_row(\n            label=f\"{source_labels[i_source]}.{detector_labels[i_detector]}.{wavelength:0.0f}nm\",\n            source=i_source,\n            detector=i_detector,\n            source_wavelength=wavelength,\n        )\n\n\n# create a NIRSDevice which contains all of the information\n# about the device configuration and arrangement\ndevice = NIRSDevice(\n    name=\"nirs_device\",\n    description=\"world's best fNIRS device\",\n    manufacturer=\"skynet\",\n    nirs_mode=\"time-domain\",\n    channels=channels,\n    sources=sources,\n    detectors=detectors,\n    # depending on which nirs_mode is selected, additional parameter values should be\n    # included. these two parameters are included because we are using time-domain NIRS\n    time_delay=1.5,  # in ns\n    time_delay_width=0.1,  # in ns\n    # specialized NIRS hardware may require additional parameters that can be defined\n    # using the `additional_parameters` field:\n    additional_parameters=\"flux_capacitor_gain = 9000; speaker_volume = 11;\",\n)\n# add the device to the NWB file\nnwb.add_device(device)\n\n\n# create a NIRSSeries timeseries containing raw NIRS data\nnirs_series = NIRSSeries(\n    name=\"nirs_data\",\n    description=\"The raw NIRS channel data\",\n    timestamps=np.arange(0, 10, 0.01),  # in seconds\n    # reference only the channels associated with this series\n    channels=DynamicTableRegion(\n        name=\"channels\",\n        description=\"an ordered map to the channels in this NIRS series\",\n        table=channels,\n        data=channels.id[:],\n    ),\n    data=np.random.rand(1000, 8),  # shape: (num timesteps, num channels)\n    unit=\"V\",\n)\n# add the series to the NWB file\nnwb.add_acquisition(nirs_series)\n\n\n# Write our test file\nfilename = \"test_nirs_file.nwb\"\nwith NWBHDF5IO(filename, \"w\") as io:\n    io.write(nwb)\n\n# Read the data back in\nwith NWBHDF5IO(filename, \"r\", load_namespaces=True) as io:\n    nwb = io.read()\n    print(nwb)\n    print(nwb.devices[\"nirs_device\"])\n    print(nwb.acquisition[\"nirs_data\"])\n```\n\nThis extension was created using [ndx-template](https://github.com/nwb-extensions/ndx-template).\n"}, "ndx-hierarchical-behavioral-data-record": {"ref": "ndx-hierarchical-behavioral-data-record", "record_url": "https://github.com/nwb-extensions/ndx-hierarchical-behavioral-data-record", "last_updated": "2022-11-15T06:20:55Z", "name": "ndx-hierarchical-behavioral-data", "version": "0.1.1", "src": "https://github.com/catalystneuro/ndx-hierarchical-behavioral-data", "pip": "https://pypi.org/project/ndx-hierarchical-behavioral-data/", "license": "BSD", "maintainers": ["bendichter", "luiztauffer"], "readme": "# ndx-hierarchical-behavioral-data Extension for NWB\n\n[![PyPI version](https://badge.fury.io/py/ndx-hierarchical-behavioral-data.svg)](https://badge.fury.io/py/ndx-hierarchical-behavioral-data)\n\n![schema schema](https://github.com/catalystneuro/ndx-hierarchical-behavioral-data/blob/master/docs/media/hierarchical_behavioral_data.png?raw=true)\n\n## Installation\n\n```\npip install ndx-hierarchical-behavioral-data\n```\n\n## Usage\nUse pre-made hierarchical transcription tables:\n\n```python\nfrom ndx_hierarchical_behavioral_data.definitions.transcription import TIPhonemes, HBTSyllables, HBTWords, HBTSentences\n\n# Phonemes level\nphonemes = TIPhonemes()\nphonemes.add_column('max_pitch', 'maximum pitch for this phoneme. NaN for unvoiced')\nfor i, p in enumerate('abcdefghijkl'):\n    phonemes.add_interval(label=p, start_time=float(i), stop_time=float(i+1), max_pitch=i**2)\n\n# Syllables level\nsyllables = HBTSyllables(lower_tier_table=phonemes)\nsyllables.add_interval(label='abc', next_tier=[0, 1, 2])\nsyllables.add_interval(label='def', next_tier=[3, 4, 5])\nsyllables.add_interval(label='ghi', next_tier=[6, 7, 8])\nsyllables.add_interval(label='jkl', next_tier=[9, 10, 11])\n\n# Words level\nwords = HBTWords(lower_tier_table=syllables)\nwords.add_column('emphasis', 'boolean indicating whether this word was emphasized')\nwords.add_interval(label='A-F', next_tier=[0, 1], emphasis=False)\nwords.add_interval(label='G-L', next_tier=[2, 3], emphasis=True)\n\n# Sentences level\nsentences = HBTSentences(lower_tier_table=words)\nsentences.add_interval(label='A-L', next_tier=[0, 1])\n```\n\nView individual tiers:\n\n```python\nsentences.to_dataframe()\n```\n<html><table border=\"1\" class=\"dataframe\"><thead><tr style=\"text-align: right;\"><th></th><th>label</th><th>start_time</th><th>stop_time</th><th>next_tier</th></tr><tr><th>id</th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><th>0</th><td>A-L</td><td>0.0</td><td>12.0</td><td>label  start_time  stop_time  \\\\id     ...</td></tr></tbody></table></html>\n\n\n```python\nwords.to_dataframe()\n```\n\n<html><table border=\"1\" class=\"dataframe\"> <thead> <tr style=\"text-align: right;\"> <th></th> <th>label</th> <th>start_time</th> <th>stop_time</th> <th>next_tier</th> <th>emphasis</th> </tr> <tr> <th>id</th> <th></th> <th></th> <th></th> <th></th> <th></th> </tr> </thead> <tbody> <tr> <th>0</th> <td>A-F</td> <td>0.0</td> <td>6.0</td> <td>label  start_time  stop_time  \\\\ id                                 0    abc         0.0        3.0    1    def         3.0        6.0     next_tier   id                                                                                                                                                                                                                           0       start_time  stop_time label  max_pitch id                                         0          0.0        1.0     a          0 1          1.0        2.0     b          1 2          2.0        3.0     c          4   1       start_time  stop_time label  max_pitch id                                         3          3.0        4.0     d          9 4          4.0        5.0     e         16 5          5.0        6.0     f         25</td> <td>False</td> </tr> <tr> <th>1</th> <td>G-L</td> <td>6.0</td> <td>12.0</td> <td>label  start_time  stop_time  \\\\ id                                 2    ghi         6.0        9.0    3    jkl         9.0       12.0     next_tier   id                                                                                                                                                                                                                           2       start_time  stop_time label  max_pitch id                                         6          6.0        7.0     g         36 7          7.0        8.0     h         49 8          8.0        9.0     i         64   3       start_time  stop_time label  max_pitch id                                         9          9.0       10.0     j         81 10        10.0       11.0     k        100 11        11.0       12.0     l        121</td> <td>True</td> </tr> </tbody> </table></html>\n\n```python\nsyllables.to_dataframe()\n```\n\n<html><table border=\"1\" class=\"dataframe\"><thead><tr style=\"text-align: right;\"><th></th><th>label</th><th>start_time</th><th>stop_time</th><th>next_tier</th></tr> <tr> <th>id</th> <th></th> <th></th> <th></th> <th></th> </tr> </thead> <tbody> <tr> <th>0</th> <td>abc</td> <td>0.0</td> <td>3.0</td> <td>start_time  stop_time label id                              0          0.0        1.0     a 1          1.0        2.0     b 2          2.0        3.0     c</td> </tr> <tr> <th>1</th> <td>def</td> <td>3.0</td> <td>6.0</td> <td>start_time  stop_time label id                              3          3.0        4.0     d 4          4.0        5.0     e 5          5.0        6.0     f</td> </tr> <tr> <th>2</th> <td>ghi</td> <td>6.0</td> <td>9.0</td> <td>start_time  stop_time label id                              6          6.0        7.0     g 7          7.0        8.0     h 8          8.0        9.0     i</td> </tr> <tr> <th>3</th> <td>jkl</td> <td>9.0</td> <td>12.0</td> <td>start_time  stop_time label id                              9          9.0       10.0     j 10        10.0       11.0     k 11        11.0       12.0     l</td> </tr> </tbody> </table></html>\n\n```python\nphonemes.to_dataframe()\n```\n\n<html><table border=\"1\" class=\"dataframe\"> <thead> <tr style=\"text-align: right;\"> <th></th> <th>start_time</th> <th>stop_time</th> <th>label</th> <th>max_pitch</th> </tr> <tr> <th>id</th> <th></th> <th></th> <th></th> <th></th> </tr> </thead> <tbody> <tr> <th>0</th> <td>0.0</td> <td>1.0</td> <td>a</td> <td>0</td> </tr> <tr> <th>1</th> <td>1.0</td> <td>2.0</td> <td>b</td> <td>1</td> </tr> <tr> <th>2</th> <td>2.0</td> <td>3.0</td> <td>c</td> <td>4</td> </tr> <tr> <th>3</th> <td>3.0</td> <td>4.0</td> <td>d</td> <td>9</td> </tr> <tr> <th>4</th> <td>4.0</td> <td>5.0</td> <td>e</td> <td>16</td> </tr> <tr> <th>5</th> <td>5.0</td> <td>6.0</td> <td>f</td> <td>25</td> </tr> <tr> <th>6</th> <td>6.0</td> <td>7.0</td> <td>g</td> <td>36</td> </tr> <tr> <th>7</th> <td>7.0</td> <td>8.0</td> <td>h</td> <td>49</td> </tr> <tr> <th>8</th> <td>8.0</td> <td>9.0</td> <td>i</td> <td>64</td> </tr> <tr> <th>9</th> <td>9.0</td> <td>10.0</td> <td>j</td> <td>81</td> </tr> <tr> <th>10</th> <td>10.0</td> <td>11.0</td> <td>k</td> <td>100</td> </tr> <tr> <th>11</th> <td>11.0</td> <td>12.0</td> <td>l</td> <td>121</td> </tr> </tbody> </table></html>\n\n\nHierarchical dataframe:\n```python\nsentences.to_hierarchical_dataframe()\n```\n<html><table border=\"1\" class=\"dataframe\"> <thead> <tr> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th>source_table</th> <th colspan=\"5\" halign=\"left\">phonemes</th> </tr> <tr> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th>label</th> <th>id</th> <th>start_time</th> <th>stop_time</th> <th>label</th> <th>max_pitch</th> </tr> <tr> <th>sentences_id</th> <th>sentences_label</th> <th>sentences_start_time</th> <th>sentences_stop_time</th> <th>words_id</th> <th>words_label</th> <th>words_start_time</th> <th>words_stop_time</th> <th>words_emphasis</th> <th>syllables_id</th> <th>syllables_label</th> <th>syllables_start_time</th> <th>syllables_stop_time</th> <th></th> <th></th> <th></th> <th></th> <th></th> </tr> </thead> <tbody> <tr> <th rowspan=\"12\" valign=\"top\">0</th> <th rowspan=\"12\" valign=\"top\">A-L</th> <th rowspan=\"12\" valign=\"top\">0.0</th> <th rowspan=\"12\" valign=\"top\">12.0</th> <th rowspan=\"6\" valign=\"top\">0</th> <th rowspan=\"6\" valign=\"top\">A-F</th> <th rowspan=\"6\" valign=\"top\">0.0</th> <th rowspan=\"6\" valign=\"top\">6.0</th> <th rowspan=\"6\" valign=\"top\">False</th> <th rowspan=\"3\" valign=\"top\">0</th> <th rowspan=\"3\" valign=\"top\">abc</th> <th rowspan=\"3\" valign=\"top\">0.0</th> <th>3.0</th> <td>0</td> <td>0.0</td> <td>1.0</td> <td>a</td> <td>0</td> </tr> <tr> <th>3.0</th> <td>1</td> <td>1.0</td> <td>2.0</td> <td>b</td> <td>1</td> </tr> <tr> <th>3.0</th> <td>2</td> <td>2.0</td> <td>3.0</td> <td>c</td> <td>4</td> </tr> <tr> <th rowspan=\"3\" valign=\"top\">1</th> <th rowspan=\"3\" valign=\"top\">def</th> <th rowspan=\"3\" valign=\"top\">3.0</th> <th>6.0</th> <td>3</td> <td>3.0</td> <td>4.0</td> <td>d</td> <td>9</td> </tr> <tr> <th>6.0</th> <td>4</td> <td>4.0</td> <td>5.0</td> <td>e</td> <td>16</td> </tr> <tr> <th>6.0</th> <td>5</td> <td>5.0</td> <td>6.0</td> <td>f</td> <td>25</td> </tr> <tr> <th rowspan=\"6\" valign=\"top\">1</th> <th rowspan=\"6\" valign=\"top\">G-L</th> <th rowspan=\"6\" valign=\"top\">6.0</th> <th rowspan=\"6\" valign=\"top\">12.0</th> <th rowspan=\"6\" valign=\"top\">True</th> <th rowspan=\"3\" valign=\"top\">2</th> <th rowspan=\"3\" valign=\"top\">ghi</th> <th rowspan=\"3\" valign=\"top\">6.0</th> <th>9.0</th> <td>6</td> <td>6.0</td> <td>7.0</td> <td>g</td> <td>36</td> </tr> <tr> <th>9.0</th> <td>7</td> <td>7.0</td> <td>8.0</td> <td>h</td> <td>49</td> </tr> <tr> <th>9.0</th> <td>8</td> <td>8.0</td> <td>9.0</td> <td>i</td> <td>64</td> </tr> <tr> <th rowspan=\"3\" valign=\"top\">3</th> <th rowspan=\"3\" valign=\"top\">jkl</th> <th rowspan=\"3\" valign=\"top\">9.0</th> <th>12.0</th> <td>9</td> <td>9.0</td> <td>10.0</td> <td>j</td> <td>81</td> </tr> <tr> <th>12.0</th> <td>10</td> <td>10.0</td> <td>11.0</td> <td>k</td> <td>100</td> </tr> <tr> <th>12.0</th> <td>11</td> <td>11.0</td> <td>12.0</td> <td>l</td> <td>121</td> </tr> </tbody> </table></html>\n\n\nHierachical columns, flattened rows:\n\n```python\nsentences.to_hierarchical_dataframe(flat_column_index=True)\n```\n\n<html><table border=\"1\" class=\"dataframe\"> <thead> <tr style=\"text-align: right;\"> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> <th>id</th> <th>start_time</th> <th>stop_time</th> <th>label</th> <th>max_pitch</th> </tr> <tr> <th>sentences_id</th> <th>sentences_label</th> <th>sentences_start_time</th> <th>sentences_stop_time</th> <th>words_id</th> <th>words_label</th> <th>words_start_time</th> <th>words_stop_time</th> <th>words_emphasis</th> <th>syllables_id</th> <th>syllables_label</th> <th>syllables_start_time</th> <th>syllables_stop_time</th> <th></th> <th></th> <th></th> <th></th> <th></th> </tr> </thead> <tbody> <tr> <th rowspan=\"12\" valign=\"top\">0</th> <th rowspan=\"12\" valign=\"top\">A-L</th> <th rowspan=\"12\" valign=\"top\">0.0</th> <th rowspan=\"12\" valign=\"top\">12.0</th> <th rowspan=\"6\" valign=\"top\">0</th> <th rowspan=\"6\" valign=\"top\">A-F</th> <th rowspan=\"6\" valign=\"top\">0.0</th> <th rowspan=\"6\" valign=\"top\">6.0</th> <th rowspan=\"6\" valign=\"top\">False</th> <th rowspan=\"3\" valign=\"top\">0</th> <th rowspan=\"3\" valign=\"top\">abc</th> <th rowspan=\"3\" valign=\"top\">0.0</th> <th>3.0</th> <td>0</td> <td>0.0</td> <td>1.0</td> <td>a</td> <td>0</td> </tr> <tr> <th>3.0</th> <td>1</td> <td>1.0</td> <td>2.0</td> <td>b</td> <td>1</td> </tr> <tr> <th>3.0</th> <td>2</td> <td>2.0</td> <td>3.0</td> <td>c</td> <td>4</td> </tr> <tr> <th rowspan=\"3\" valign=\"top\">1</th> <th rowspan=\"3\" valign=\"top\">def</th> <th rowspan=\"3\" valign=\"top\">3.0</th> <th>6.0</th> <td>3</td> <td>3.0</td> <td>4.0</td> <td>d</td> <td>9</td> </tr> <tr> <th>6.0</th> <td>4</td> <td>4.0</td> <td>5.0</td> <td>e</td> <td>16</td> </tr> <tr> <th>6.0</th> <td>5</td> <td>5.0</td> <td>6.0</td> <td>f</td> <td>25</td> </tr> <tr> <th rowspan=\"6\" valign=\"top\">1</th> <th rowspan=\"6\" valign=\"top\">G-L</th> <th rowspan=\"6\" valign=\"top\">6.0</th> <th rowspan=\"6\" valign=\"top\">12.0</th> <th rowspan=\"6\" valign=\"top\">True</th> <th rowspan=\"3\" valign=\"top\">2</th> <th rowspan=\"3\" valign=\"top\">ghi</th> <th rowspan=\"3\" valign=\"top\">6.0</th> <th>9.0</th> <td>6</td> <td>6.0</td> <td>7.0</td> <td>g</td> <td>36</td> </tr> <tr> <th>9.0</th> <td>7</td> <td>7.0</td> <td>8.0</td> <td>h</td> <td>49</td> </tr> <tr> <th>9.0</th> <td>8</td> <td>8.0</td> <td>9.0</td> <td>i</td> <td>64</td> </tr> <tr> <th rowspan=\"3\" valign=\"top\">3</th> <th rowspan=\"3\" valign=\"top\">jkl</th> <th rowspan=\"3\" valign=\"top\">9.0</th> <th>12.0</th> <td>9</td> <td>9.0</td> <td>10.0</td> <td>j</td> <td>81</td> </tr> <tr> <th>12.0</th> <td>10</td> <td>10.0</td> <td>11.0</td> <td>k</td> <td>100</td> </tr> <tr> <th>12.0</th> <td>11</td> <td>11.0</td> <td>12.0</td> <td>l</td> <td>121</td> </tr> </tbody> </table></html>\n\nDenormalized dataframe:\n```python\nsentences.to_denormalized_dataframe()\n```\n\n<html><table border=\"1\" class=\"dataframe\"> <thead> <tr> <th>source_table</th> <th colspan=\"4\" halign=\"left\">sentences</th> <th colspan=\"5\" halign=\"left\">words</th> <th colspan=\"4\" halign=\"left\">syllables</th> <th colspan=\"5\" halign=\"left\">phonemes</th> </tr> <tr> <th>label</th> <th>id</th> <th>label</th> <th>start_time</th> <th>stop_time</th> <th>id</th> <th>label</th> <th>start_time</th> <th>stop_time</th> <th>emphasis</th> <th>id</th> <th>label</th> <th>start_time</th> <th>stop_time</th> <th>id</th> <th>start_time</th> <th>stop_time</th> <th>label</th> <th>max_pitch</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>0</td> <td>A-F</td> <td>0.0</td> <td>6.0</td> <td>False</td> <td>0</td> <td>abc</td> <td>0.0</td> <td>3.0</td> <td>0</td> <td>0.0</td> <td>1.0</td> <td>a</td> <td>0</td> </tr> <tr> <th>1</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>0</td> <td>A-F</td> <td>0.0</td> <td>6.0</td> <td>False</td> <td>0</td> <td>abc</td> <td>0.0</td> <td>3.0</td> <td>1</td> <td>1.0</td> <td>2.0</td> <td>b</td> <td>1</td> </tr> <tr> <th>2</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>0</td> <td>A-F</td> <td>0.0</td> <td>6.0</td> <td>False</td> <td>0</td> <td>abc</td> <td>0.0</td> <td>3.0</td> <td>2</td> <td>2.0</td> <td>3.0</td> <td>c</td> <td>4</td> </tr> <tr> <th>3</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>0</td> <td>A-F</td> <td>0.0</td> <td>6.0</td> <td>False</td> <td>1</td> <td>def</td> <td>3.0</td> <td>6.0</td> <td>3</td> <td>3.0</td> <td>4.0</td> <td>d</td> <td>9</td> </tr> <tr> <th>4</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>0</td> <td>A-F</td> <td>0.0</td> <td>6.0</td> <td>False</td> <td>1</td> <td>def</td> <td>3.0</td> <td>6.0</td> <td>4</td> <td>4.0</td> <td>5.0</td> <td>e</td> <td>16</td> </tr> <tr> <th>5</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>0</td> <td>A-F</td> <td>0.0</td> <td>6.0</td> <td>False</td> <td>1</td> <td>def</td> <td>3.0</td> <td>6.0</td> <td>5</td> <td>5.0</td> <td>6.0</td> <td>f</td> <td>25</td> </tr> <tr> <th>6</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>1</td> <td>G-L</td> <td>6.0</td> <td>12.0</td> <td>True</td> <td>2</td> <td>ghi</td> <td>6.0</td> <td>9.0</td> <td>6</td> <td>6.0</td> <td>7.0</td> <td>g</td> <td>36</td> </tr> <tr> <th>7</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>1</td> <td>G-L</td> <td>6.0</td> <td>12.0</td> <td>True</td> <td>2</td> <td>ghi</td> <td>6.0</td> <td>9.0</td> <td>7</td> <td>7.0</td> <td>8.0</td> <td>h</td> <td>49</td> </tr> <tr> <th>8</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>1</td> <td>G-L</td> <td>6.0</td> <td>12.0</td> <td>True</td> <td>2</td> <td>ghi</td> <td>6.0</td> <td>9.0</td> <td>8</td> <td>8.0</td> <td>9.0</td> <td>i</td> <td>64</td> </tr> <tr> <th>9</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>1</td> <td>G-L</td> <td>6.0</td> <td>12.0</td> <td>True</td> <td>3</td> <td>jkl</td> <td>9.0</td> <td>12.0</td> <td>9</td> <td>9.0</td> <td>10.0</td> <td>j</td> <td>81</td> </tr> <tr> <th>10</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>1</td> <td>G-L</td> <td>6.0</td> <td>12.0</td> <td>True</td> <td>3</td> <td>jkl</td> <td>9.0</td> <td>12.0</td> <td>10</td> <td>10.0</td> <td>11.0</td> <td>k</td> <td>100</td> </tr> <tr> <th>11</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>1</td> <td>G-L</td> <td>6.0</td> <td>12.0</td> <td>True</td> <td>3</td> <td>jkl</td> <td>9.0</td> <td>12.0</td> <td>11</td> <td>11.0</td> <td>12.0</td> <td>l</td> <td>121</td> </tr> </tbody> </table></html>\n\nDenormalized dataframe with flattened columns:\n```python\nsentences.to_denormalized_dataframe(flat_column_index=True)\n```\n\n<html><table border=\"1\" class=\"dataframe\"> <thead> <tr style=\"text-align: right;\"> <th></th> <th>sentences_id</th> <th>sentences_label</th> <th>sentences_start_time</th> <th>sentences_stop_time</th> <th>words_id</th> <th>words_label</th> <th>words_start_time</th> <th>words_stop_time</th> <th>words_emphasis</th> <th>syllables_id</th> <th>syllables_label</th> <th>syllables_start_time</th> <th>syllables_stop_time</th> <th>id</th> <th>start_time</th> <th>stop_time</th> <th>label</th> <th>max_pitch</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>0</td> <td>A-F</td> <td>0.0</td> <td>6.0</td> <td>False</td> <td>0</td> <td>abc</td> <td>0.0</td> <td>3.0</td> <td>0</td> <td>0.0</td> <td>1.0</td> <td>a</td> <td>0</td> </tr> <tr> <th>1</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>0</td> <td>A-F</td> <td>0.0</td> <td>6.0</td> <td>False</td> <td>0</td> <td>abc</td> <td>0.0</td> <td>3.0</td> <td>1</td> <td>1.0</td> <td>2.0</td> <td>b</td> <td>1</td> </tr> <tr> <th>2</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>0</td> <td>A-F</td> <td>0.0</td> <td>6.0</td> <td>False</td> <td>0</td> <td>abc</td> <td>0.0</td> <td>3.0</td> <td>2</td> <td>2.0</td> <td>3.0</td> <td>c</td> <td>4</td> </tr> <tr> <th>3</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>0</td> <td>A-F</td> <td>0.0</td> <td>6.0</td> <td>False</td> <td>1</td> <td>def</td> <td>3.0</td> <td>6.0</td> <td>3</td> <td>3.0</td> <td>4.0</td> <td>d</td> <td>9</td> </tr> <tr> <th>4</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>0</td> <td>A-F</td> <td>0.0</td> <td>6.0</td> <td>False</td> <td>1</td> <td>def</td> <td>3.0</td> <td>6.0</td> <td>4</td> <td>4.0</td> <td>5.0</td> <td>e</td> <td>16</td> </tr> <tr> <th>5</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>0</td> <td>A-F</td> <td>0.0</td> <td>6.0</td> <td>False</td> <td>1</td> <td>def</td> <td>3.0</td> <td>6.0</td> <td>5</td> <td>5.0</td> <td>6.0</td> <td>f</td> <td>25</td> </tr> <tr> <th>6</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>1</td> <td>G-L</td> <td>6.0</td> <td>12.0</td> <td>True</td> <td>2</td> <td>ghi</td> <td>6.0</td> <td>9.0</td> <td>6</td> <td>6.0</td> <td>7.0</td> <td>g</td> <td>36</td> </tr> <tr> <th>7</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>1</td> <td>G-L</td> <td>6.0</td> <td>12.0</td> <td>True</td> <td>2</td> <td>ghi</td> <td>6.0</td> <td>9.0</td> <td>7</td> <td>7.0</td> <td>8.0</td> <td>h</td> <td>49</td> </tr> <tr> <th>8</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>1</td> <td>G-L</td> <td>6.0</td> <td>12.0</td> <td>True</td> <td>2</td> <td>ghi</td> <td>6.0</td> <td>9.0</td> <td>8</td> <td>8.0</td> <td>9.0</td> <td>i</td> <td>64</td> </tr> <tr> <th>9</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>1</td> <td>G-L</td> <td>6.0</td> <td>12.0</td> <td>True</td> <td>3</td> <td>jkl</td> <td>9.0</td> <td>12.0</td> <td>9</td> <td>9.0</td> <td>10.0</td> <td>j</td> <td>81</td> </tr> <tr> <th>10</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>1</td> <td>G-L</td> <td>6.0</td> <td>12.0</td> <td>True</td> <td>3</td> <td>jkl</td> <td>9.0</td> <td>12.0</td> <td>10</td> <td>10.0</td> <td>11.0</td> <td>k</td> <td>100</td> </tr> <tr> <th>11</th> <td>0</td> <td>A-L</td> <td>0.0</td> <td>12.0</td> <td>1</td> <td>G-L</td> <td>6.0</td> <td>12.0</td> <td>True</td> <td>3</td> <td>jkl</td> <td>9.0</td> <td>12.0</td> <td>11</td> <td>11.0</td> <td>12.0</td> <td>l</td> <td>121</td> </tr> </tbody> </table></html>\n\n\n\nThis extension was created using [ndx-template](https://github.com/nwb-extensions/ndx-template).\n"}, "ndx-sound-record": {"ref": "ndx-sound-record", "record_url": "https://github.com/nwb-extensions/ndx-sound-record", "last_updated": "2022-11-15T07:17:28Z", "name": "ndx-sound", "version": "0.2.0", "src": "https://github.com/catalystneuro/ndx-sound/", "pip": "https://pypi.org/project/ndx-sound/", "license": "BSD", "maintainers": ["weiglszonja", "bendichter"], "readme": "![PyPI](https://img.shields.io/pypi/v/ndx-sound?color=blue)\n\n# ndx-sound Extension for NWB\n\nNWB extension for sounds.\n\n## Installation\n\n```shell\npip install ndx-sound\n```\n\n## Usage\n\n## Python\n\n### Add to an NWB file\n```python\nfrom pynwb import NWBFile\nfrom scipy.io import wavfile\n\nfrom ndx_sound import AcousticWaveformSeries\n\n# The file path to the audio file\nfile_path = \"audio_data.wav\"\n\n# Read the audio file to get the rate of the recording and the waveform\nsampling_rate, samples = wavfile.read(file_path)\n\n# Create an AcousticWaveformSeries object with a given name and description\nacoustic_waveform_series = AcousticWaveformSeries(\n    name=\"acoustic_stimulus\",\n    data=samples,\n    rate=sampling_rate,\n    description=\"acoustic stimulus\",\n)\n\n# Create an NWBFile object where this AcousticWaveformSeries can be added to\nnwbfile = NWBFile(\n    session_description=...,\n    identifier=...,\n    session_start_time=...,\n)\n\n# If a recording of behavior, add to acquisition\nnwbfile.add_acquisition(acoustic_waveform_series)\n\n# If a stimulus, add to stimulus\nnwbfile.add_stimulus(acoustic_waveform_series)\n```\n\n### Visualization\n\n#### Static widgets\nUse `plot_sound` to visualize the waveform series and the spectrogram.\nFor longer recordings, specify the `time_window` argument for the start and end time\nof the recording to be shown.\n```python\nfrom ndx_sound.widgets import plot_sound\n\nplot_sound(nwbfile.stimulus[\"acoustic_stimulus\"])\n\n# Show only from 5 to 15 seconds\nplot_sound(nwbfile.stimulus[\"acoustic_stimulus\"], time_window=(5, 15))\n```\n\n![](https://github.com/catalystneuro/ndx-sound/blob/main/ndx_sound_plot_timewindow.png)\n\nUse `acoustic_waveform_widget` to include an Audio element that plays the sound.\n\n```python\nfrom ndx_sound.widgets import acoustic_waveform_widget\n\nacoustic_waveform_widget(nwbfile.stimulus[\"acoustic_stimulus\"], time_window=(5, 15))\n```\n\n![](https://github.com/catalystneuro/ndx-sound/blob/main/acoustic_waveform_widget_timewindow.png)\n\n#### Interactive widgets\nUse `AcousticWaveformWidget` to use a slider for interactively scrolling through the\nrecording and a button for changing the duration of the sound that is being shown.\n\n```python\nfrom ndx_sound.widgets import AcousticWaveformWidget\n\nAcousticWaveformWidget(nwbfile.stimulus[\"acoustic_stimulus\"])\n```\n\n![](https://github.com/catalystneuro/ndx-sound/blob/main/interactive_widget.png)\n\n### nwbwidgets\nUse `load_widgets` to load the interactive sound widget into `nwb2widget`.\n\n```python\nfrom ndx_sound.widgets import load_widgets\nfrom nwbwidgets import nwb2widget\n\nload_widgets()\n\nnwb2widget(nwbfile)\n```\n\n![](https://github.com/catalystneuro/ndx-sound/blob/main/ndx_sound_in_nwbwidgets.png)\n\n#### nwbwidgets and HDF5IO\nWhen using `nwb2widget` with an NWB file that is read from disk, make sure to have\n`load_widgets` imported within the same Jupyter cell where your data is being loaded.\n\n```python\nfrom pynwb import NWBHDF5IO\nfrom ndx_sound.widgets import load_widgets\nfrom nwbwidgets import nwb2widget\n\nload_widgets()\n\n\nio = NWBHDF5IO(\"audio.nwb\", mode=\"r\", load_namespaces=True)\nnwbfile = io.read()\nnwb2widget(nwbfile)\n```\n\n---\nThis extension was created using [ndx-template](https://github.com/nwb-extensions/ndx-template).\n"}, "ndx-extract-record": {"ref": "ndx-extract-record", "record_url": "https://github.com/nwb-extensions/ndx-extract-record", "last_updated": "2022-11-15T07:23:53Z", "name": "ndx-extract", "version": "0.2.0", "src": "https://github.com/catalystneuro/ndx-extract", "pip": "https://pypi.org/project/ndx-extract/0.2.0/", "license": "BSD", "maintainers": ["bendichter", "weiglszonja"], "readme": "# ndx-extract Extension for NWB\n\nAuthor: Cesar Echavarria\n\nThis extension allows for the storage of configuration options used by the [EXTRACT](https://github.com/schnitzer-lab/EXTRACT-public) tool for calcium imaging.\n\n\n## Usage\n\n\n### Python\nInstall the extension from [PyPI](https://pypi.org/project/ndx-extract/)\n```shell\npip install ndx-extract\n```\nUsage:\n```python\nfrom datetime import datetime\nfrom ndx_extract import EXTRACTSegmentation\nfrom pynwb import NWBFile, NWBHDF5IO\n\n# Create the NWBfile\nnwbfile = NWBFile(\n    session_description=\"The mouse in open exploration.\",\n    identifier=\"Mouse5_Day3\",\n    session_start_time=datetime.now().astimezone(),\n)\n# Create the processing module\nophys_module = nwbfile.create_processing_module(\n    name=\"ophys\",\n    description=\"optical physiology processed data\",\n)\n# Create the segmentation object and define the configuration properties\n# The properties that can be defined are listed at spec/ndx-EXTRACT.extensions.yaml\nimage_segmentation = EXTRACTSegmentation(\n            name=\"ImageSegmentation\",\n            version=\"1.1.0\",\n            preprocess=True,\n            trace_output_option=\"nonneg\",\n)\n# Add this image segmentation to the processing module\nophys_module.add(image_segmentation)\n\n# Writing the NWB file\nwith NWBHDF5IO(\"image_segmentation.nwb\", mode=\"w\") as io:\n    io.write(nwbfile)\n\n# Reading the NWB file and accessing the segmentation parameters\nwith NWBHDF5IO(\"image_segmentation.nwb\", mode=\"r\") as io:\n    nwbfile_in = io.read()\n    nwbfile_in.processing[\"ophys\"].data_interfaces[\"ImageSegmentation\"].version\n    nwbfile_in.processing[\"ophys\"].data_interfaces[\"ImageSegmentation\"].preprocess\n    nwbfile_in.processing[\"ophys\"].data_interfaces[\"ImageSegmentation\"].trace_output_option\n```\n\nRunning the tests:\n```shell\n python -m unittest src/pynwb/tests/test_extract.py\n```\n\n### MATLAB\ninstall:\n```matlab\ngenerateExtension('/path/to/ndx-extract/spec/ndx-extract.namespace.yaml');\n```\n\nwrite:\n```matlab\n% define NWB file\nnwb = NwbFile( ...\n    'session_description', 'mouse in open exploration', ...\n    'identifier', 'Mouse5_Day3', ...\n    'session_start_time', datetime(2018, 4, 25, 2, 30, 3) ...\n);\n% define processing module\nophys_module = types.core.ProcessingModule( ...\n    'description', 'test processing module' ...\n);\nnwb.processing.set('ophys', ophys_module);\n% define segmentation\nimg_seg = types.ndx_extract.EXTRACTSegmentation();\n% set segmentation properties\nimg_seg.trace_output_option = 'nonneg';\nimg_seg.save_all_found = false;\nimg_seg.dendrite_aware = false;\nimg_seg.adaptive_kappa = false;\nimg_seg.use_sparse_arrays = false;\nimg_seg.dendrite_aware = 0;\nimg_seg.hyperparameter_tuning_flag = false;\nimg_seg.remove_duplicate_cells = false;\nimg_seg.max_iter = 6;\nimg_seg.S_init = rand(100,10);\nimg_seg.T_init = rand(100,10);\nimg_seg.preprocess = true;\nimg_seg.fix_zero_FOV_strips = false;\nimg_seg.medfilt_outlier_pixels = false;\nimg_seg.skip_dff = false;\nimg_seg.baseline_quantile = .4;\nimg_seg.skip_highpass = false;\nimg_seg.spatial_highpass_cutoff = 0;\nimg_seg.temporal_denoising = false;\nimg_seg.remove_background = true;\nimg_seg.cellfind_filter_type = 'butter';\nimg_seg.spatial_lowpass_cutoff = 2;\nimg_seg.moving_radius = 3;\nimg_seg.cellfind_min_snr = 1;\nimg_seg.cellfind_max_steps = 1000;\nimg_seg.cellfind_kappa_std_ratio = 1;\nimg_seg.init_with_gaussian = false;\nimg_seg.kappa_std_ratio = 1;\nimg_seg.downsample_time_by = 'auto';\nimg_seg.downsample_space_by = 'auto';\nimg_seg.min_radius_after_downsampling = 5;\nimg_seg.min_tau_after_downsampling = 5;\nimg_seg.reestimate_S_if_downsampled = false;\nimg_seg.reestimate_T_if_downsampled = true;\nimg_seg.crop_circular = false;\nimg_seg.movie_mask = randi(2,100,100)-1;\nimg_seg.smoothing_ratio_x2y = 0;\nimg_seg.compact_output = true;\nimg_seg.cellfind_numpix_threshold = 9;\nimg_seg.high2low_brightness_ratio = Inf;\nimg_seg.l1_penalty_factor = 0;\nimg_seg.T_lower_snr_threshold = 10;\nimg_seg.smooth_T = false;\nimg_seg.smooth_S = true;\nimg_seg.max_iter_S = 100;\nimg_seg.max_iter_T = 100;\nimg_seg.TOL_sub = 1.0000e-06;\nimg_seg.TOL_main = 0.0100;\nimg_seg.avg_cell_radius = 0;\nimg_seg.T_min_snr = 10;\nimg_seg.size_lower_limit = .1000;\nimg_seg.size_upper_limit = 10;\nimg_seg.temporal_corrupt_thresh = 0.7000;\nimg_seg.spatial_corrupt_thresh = 0.7000;\nimg_seg.eccent_thresh = 6;\nimg_seg.low_ST_index_thresh = 0.0100;\nimg_seg.low_ST_corr_thresh = 0;\nimg_seg.S_dup_corr_thresh = 0.9500;\nimg_seg.T_dup_corr_thresh = 0.9500;\nimg_seg.confidence_thresh = 0.8000;\nimg_seg.high_ST_index_thresh = 0.8000;\nophys_module.nwbdatainterface.set('ImgSegmentation', img_seg);\nnwbExport(nwb, 'test_123.nwb');\n```\n\nrun tests:\n```matlab\ncd /path/to/ndx-extract/src/matnwb/tests\nresults = test_ndx_extract()\n```\n"}, "ndx-photometry-record": {"ref": "ndx-photometry-record", "record_url": "https://github.com/nwb-extensions/ndx-photometry-record", "last_updated": "2022-12-01T18:03:38Z", "name": "ndx-photometry", "version": "0.1.0", "src": "https://github.com/catalystneuro/ndx-photometry", "pip": "https://pypi.org/project/ndx-photometry/", "license": "BSD", "maintainers": ["bendichter"], "readme": "# ndx-photometry Extension for NWB\n[![Build Status](https://travis-ci.com/akshay-jaggi/ndx-photometry.svg?branch=master)](https://travis-ci.com/akshay-jaggi/ndx-photometry)\n[![Documentation Status](https://readthedocs.org/projects/ndx-photometry/badge/?version=latest)](https://ndx-photometry.readthedocs.io/en/latest/?badge=latest)\n\n![NWB - Photometry](https://user-images.githubusercontent.com/844306/144680873-3e2d957f-97ff-45cb-b625-517f5e7dfb9f.png)\n\n## Introduction\nThis is an NWB extension for storing photometry recordings and associated metadata. This extension stores photometry information across three folders in the NWB file: acquisition, processing, and general. The acquisiton folder contains an ROIResponseSeries (inherited from `pynwb.ophys`), which references rows of a FibersTable rather than 2 Photon ROIs. The new types for this extension are in metadata and processing\n\n### Metadata\n1. `FibersTable` stores rows for each fiber with information about the location, excitation, source, photodetector, fluorophore, and more (associated with each fiber). \n2. `ExcitationSourcesTable` stores rows for each excitation source with information about the peak wavelength, source type, and the commanded voltage series of type `CommandedVoltageSeries`\n3. `PhotodectorsTable` stores rows for each photodetector with information about the peak wavelength, type, etc. \n4. `FluorophoresTable` stores rows for each fluorophore with information about the fluorophore itself and the injeciton site. \n\n### Processing\n1. `DeconvoledROIResponseSeries` stores DfOverF and Fluorescence traces and extends `ROIResponseSeries` to contain information about the deconvolutional and downsampling procedures performed.\n\n\nThis extension was developed by Akshay Jaggi, Ben Dichter, and Ryan Ly. \n\n\n## Installation\n\n```\npip install ndx-photometry\n```\n\n\n## Usage\n\n```python\nimport datetime\nimport numpy as np\n\nfrom pynwb import NWBHDF5IO, NWBFile\nfrom pynwb.core import DynamicTableRegion\nfrom pynwb.ophys import RoiResponseSeries\nfrom ndx_photometry import (\n    FibersTable,\n    PhotodetectorsTable,\n    ExcitationSourcesTable,\n    DeconvolvedRoiResponseSeries,\n    MultiCommandedVoltage,\n    FiberPhotometry,\n    FluorophoresTable\n)\n\n\nnwbfile = NWBFile(\n    session_description=\"session_description\",\n    identifier=\"identifier\",\n    session_start_time=datetime.datetime.now(datetime.timezone.utc),\n)\n\n# In the next ten calls or so, we'll set up the metadata from the bottom of the metadata tree up\n# You can follow along here: \n\n# Create a commanded voltage container, this can store one or more commanded voltage series\nmulti_commanded_voltage = MultiCommandedVoltage(\n    name=\"MyMultiCommandedVoltage\",\n)\n\n# Add a commanded voltage series to this container\ncommandedvoltage_series = (\n    multi_commanded_voltage.create_commanded_voltage_series(\n        name=\"commanded_voltage\",\n        data=[1.0, 2.0, 3.0],\n        frequency=30.0,\n        power=500.0,\n        rate=30.0,\n    )\n)\n\n# Create an excitation sources table\nexcitationsources_table = ExcitationSourcesTable(\n    description=\"excitation sources table\"\n)\n\n# Add one row to the table per excitation source\n# You can repeat this in a for-loop for many sources\nexcitationsources_table.add_row(\n    peak_wavelength=700.0,\n    source_type=\"laser\",\n    commanded_voltage=commandedvoltage_series,\n)\n\nphotodetectors_table = PhotodetectorsTable(\n    description=\"photodetectors table\"\n)\n\n# Add one row to the table per photodetector\nphotodetectors_table.add_row(\n    peak_wavelength=500.0, \n    type=\"PMT\", \n    gain=100.0\n)\n\n\nfluorophores_table = FluorophoresTable(\n    description='fluorophores'\n)\n\nfluorophores_table.add_row(\n    label='dlight',\n    location='VTA',\n    coordinates=(3.0,2.0,1.0)\n)\n\nfibers_table = FibersTable(\n    description=\"fibers table\"\n)\n\n# Here we add the metadata tables to the metadata section\nnwbfile.add_lab_meta_data(\n    FiberPhotometry(\n        fibers=fibers_table,\n        excitation_sources=excitationsources_table,\n        photodetectors=photodetectors_table,\n        fluorophores=fluorophores_table\n    )\n)\n\n# Important: we add the fibers to the fibers table _after_ adding the metadata\n# This ensures that we can find this data in their tables of origin\nfibers_table.add_fiber(\n    excitation_source=0, #integers indicated rows of excitation sources table\n    photodetector=0,\n    fluorophores=[0], #potentially multiple fluorophores, so list of indices\n    location='my location',\n    notes='notes'\n)\n\n# Here we set up a list of fibers that our recording came from\nfibers_ref = DynamicTableRegion(\n    name=\"rois\", \n    data=[0], # potentially multiple fibers\n    description=\"source fibers\", \n    table=fibers_table\n)\n\n# Create a raw roiresponseseries, this is your main acquisition\nroi_response_series = RoiResponseSeries(\n    name=\"roi_response_series\",\n    description=\"my roi response series\",\n    data=np.random.randn(100, 1),\n    unit='F',\n    rate=30.0,\n    rois=fibers_ref,\n)\n\n# This is your processed data \ndeconv_roi_response_series = DeconvolvedRoiResponseSeries(\n    name=\"DeconvolvedRoiResponseSeries\",\n    description=\"my roi response series\",\n    data=np.random.randn(100, 1),\n    unit='F',\n    rate=30.0,\n    rois=fibers_ref,\n    raw=roi_response_series,\n)\n\nophys_module = nwbfile.create_processing_module(\n    name=\"ophys\", description=\"fiber photometry\"\n)\n\nophys_module.add(multi_commanded_voltage)\nnwbfile.add_acquisition(roi_response_series)\nophys_module.add(deconv_roi_response_series)\n\n# write nwb file\nfilename = 'test.nwb'\nwith NWBHDF5IO(filename, 'w') as io:\n    io.write(nwbfile)\n    \n# read nwb file and check its contents\nwith NWBHDF5IO(filename, 'r', load_namespaces=True) as io:\n    nwbfile = io.read()\n    # Access and print information about the acquisition\n    print(nwbfile.acquisition[\"roi_response_series\"])\n    # Access and print information about the processed data\n    print(nwbfile.processing['ophys'][\"DeconvolvedRoiResponseSeries\"])\n    # Access and print all of the metadata\n    print(nwbfile.lab_meta_data)\n```\n\nThis extension was created using [ndx-template](https://github.com/nwb-extensions/ndx-template).\n"}}